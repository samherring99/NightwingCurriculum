# Module 4: Language-Image Pretraining and Diffusion Models

## Introduction

[TODO] Introduction on what we aim to cover here and why

## Projects

### Project 1 - Contrastive Language Image Pretraining

[TODO] Project 1 description brief

#### Goals: 

- Review concepts of probabilistic modeling and diffusion
- Understand embeddings like CLIP

#### Readings:
- ðŸ“– [OpenAI CLIP](https://openai.com/research/clip)
- ðŸ“– [Multiomodal Embeddings](https://towardsdatascience.com/clip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72)

#### Videos:
- ðŸ“º [OpenAI CLIP Explained](https://www.youtube.com/watch?v=T9XSU0pKX2E)

### Project 2 - Diffusion Models

[TODO] Project 2 description brief

#### Goals: 

- Review the architecture of Stable Diffusion and how CLIP could be involved
- Understand how diffusion models are constructed and utilized

#### Readings:
- ðŸ“– [OpenAI DALLE](https://openai.com/research/dall-e)
- ðŸ“– [StableDiffusion Illustrated](https://jalammar.github.io/illustrated-stable-diffusion/)
- ðŸ“– [Diffusion Models Introduction](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)
- ðŸ“– [Harvard StableDiffusion Tutorial](https://scholar.harvard.edu/sites/scholar.harvard.edu/files/binxuw/files/stable_diffusion_a_tutorial.pdf)

#### Videos:
- ðŸ“º [Computerphile AI Image Generation](https://www.youtube.com/watch?v=1CIpzeNxIhU)
- ðŸ“º [StableDiffusion Explained](https://www.youtube.com/watch?v=RGBNdD3Wn-g)

### Conclusion:

[TODO] Cover everything we should have learned in these projects
