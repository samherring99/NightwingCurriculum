{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 0 Project 1: Data Collection\n",
    "\n",
    "Implement a data collection pipeline from a sample source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: DATA ACCESS\n",
    "- Find a data source (Kaggle, Wikipedia, web scraping, etc.)\n",
    "- Get access to the [data](https://www.gutenberg.org/cache/epub/2554/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# PROJECT DESCRIPTION:\n",
    "# The goal of this project is to pick a data source, colelct the data, and format it to be used for NLP\n",
    "# tasks. This project should be very basic to start, it just needs to cover the inital steps of \n",
    "# data collection. More on preprocessing and tokenization in the next projects.\n",
    "\n",
    "# Project Gutenberg Crime And Punishment\n",
    "resp = requests.get(\"https://www.gutenberg.org/cache/epub/2554/pg2554.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: INITIAL DATA COLLECTION\n",
    "- Perform initial collection steps like filtering and saving to a file\n",
    "- Using regex to extract important text from the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags for text filtering\n",
    "start = \"*** START OF THE PROJECT GUTENBERG EBOOK CRIME AND PUNISHMENT ***\"\n",
    "end = \"*** END OF THE PROJECT GUTENBERG EBOOK CRIME AND PUNISHMENT ***\"\n",
    "\n",
    "# Grab the text body from the document\n",
    "pattern = re.compile(f\"{re.escape(start)}(.*?)\\n{re.escape(end)}\", re.DOTALL)\n",
    "text = pattern.findall(resp.text)\n",
    "result = \"\\n\".join(text)\n",
    "\n",
    "# Save the text body to a local file\n",
    "if not os.path.exists(\"./crime_and_punishment.txt\"):\n",
    "    with open(\"crime_and_punishment.txt\", \"w\") as file:\n",
    "        file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: BASIC DATA ORGANIZATION\n",
    "- Peform steps here to extract important info from your collected data\n",
    "- This step still falls under 'Dataset Generation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the count of all words in a given text body\n",
    "def count_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: DISPLAY OUTPUTS\n",
    "- Display collected data points from your data source\n",
    "- We now should have a 'usable' dataset of values from a given data source to perform further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word counts, put it in a Pandas dataframe, and sort by count\n",
    "word_count = count_words(result)\n",
    "df = pd.DataFrame(list(word_count.items()), columns=['Word', 'Count'])\n",
    "sorted_df = df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Print the result\n",
    "print(sorted_df)\n",
    "print(sorted_df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
