{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Project 2: Word2Vec and BERT\n",
    "\n",
    "Implement Word2Vec and BERT and play around with them\n",
    "\n",
    "Note: needs gensim installed for word2vec to work properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: IMPORTS\n",
    "- Import the necessary libraries to get Word2Vec to work properly\n",
    "- Download the 'punkt' package from nltk to get the word tokenization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: LOAD THE DATA FILE\n",
    "- Load the file containing text you want to embed\n",
    "- Norm MacDonald's Wikipedia page is included in `data.txt`` as an example here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with open(\"data.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        lines.append(line.strip()) # Strip whitespace out\n",
    "\n",
    "lines = list(set(lines))\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: TOKENIZE AND INITIALIZE WORD2VEC MODEL\n",
    "- Tokenize the text into a vector format using `nltk.word_tokenize()`\n",
    "- Set up the Word2Vec model to be able to embed the vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = [nltk.word_tokenize(line) for line in lines]\n",
    "\n",
    "print(vector)\n",
    "\n",
    "# Chose vector size as 32 arbitrarily here as an example\n",
    "model = Word2Vec(vector, min_count=1, vector_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: FIND SIMILARITIES AND DO VECTOR MATH\n",
    "- Find the most similar embeddings to a given word from the corpus\n",
    "- Using the common examples of vector math, add and subtract vectors to see the resulting word similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word similarity\n",
    "print(model.wv.most_similar(\"Norm\"))\n",
    "\n",
    "# Vector math\n",
    "vec = model.wv['Norm'] + model.wv['Macdonald'] - model.wv['Donald']\n",
    "print(model.wv.most_similar([vec]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
